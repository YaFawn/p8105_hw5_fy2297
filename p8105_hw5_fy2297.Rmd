---
title: "p8105_hw5_fy2297"
output: github_document
---

```{r}
# load libraries
library(tidyverse)
library(rvest)
library(httr)
library(purrr)
library(patchwork)
```

# Problem 1


# Problem 2
```{r}
# import data
url = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
homicide_df = read_csv(url) %>% 
  janitor::clean_names()
```

```{r echo=FALSE}
# data for raw data description
n_row = nrow(homicide_df)
n_col = ncol(homicide_df)
```
raw data description:
The raw dataset has `r n_col` variables and `r n_row` observations. The main variables are reported date, victim race, sex, age and its corresponding city and state.

```{r}
# data manipulation
homicide_df = 
  homicide_df %>% 
  mutate(
    city_state = paste(city, state, sep = ","),
    disposition = ifelse(disposition == "Closed by arrest", "resolved", "unresolved")
  )
# create a new dataset and find the total number of homicides and the number of unsolved homicides within cities
homicide_summary_df =
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition == "unresolved")
  )
```

```{r}
# About Baltimore, MD
Baltimore_df =  
  homicide_summary_df %>% 
  filter(city_state == "Baltimore,MD")

test_stats_Baltimore = 
prop.test(
  Baltimore_df$unsolved_homicides,Baltimore_df$total_homicides) %>% 
  broom::tidy()
```
The estimated proportion of unsolved homicides in Baltimore,MD is about 64.6% and the confidence interval is [62.8%, 66.3%].

```{r}
# find statistics for all cities
test_stats_all = 
  homicide_summary_df %>% 
  mutate(
    test_stats = map2(unsolved_homicides, total_homicides, ~prop.test(.x, .y)),
    test_stats = map(test_stats, broom::tidy)
  ) %>% 
  unnest() %>% 
  arrange(estimate) %>% 
  select(
    city_state, estimate, conf.low, conf.high
  )
```

```{r}
# create a plot that shows the estimates and CIs for each city
test_stats_all %>% 
  filter(city_state != "Tulsa,AL") %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) + geom_point() + geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(title = "Unsolved Homicide Estimates and CIs",x = "City/State", y = "Proportions of Unsolved Homicides") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.9, hjust = 1)) +
  theme(plot.title = element_text(hjust = 0.5)) 
```
In the previous part of the problem, Tulsa,AL was not removed from the dataset of statistics because it didn't influence anything. However, when making the plot, it was filtered out of the dataset to make the plot look more beautiful and tidy.

# Problem 3
```{r}
# write a function
test_func = function(n = 30, mu, sigma = 5){
  sim_data = tibble(
    x = rnorm(n=n, mean = mu, sd = sigma)
  )
  sim_data %>% 
    summarize(
      t_test_stats = t.test(x, mu = 0, conf.level = 0.95)
     %>% 
    broom::tidy() %>% 
    select(estimate, p.value)
    )
}

# generate 5000 datasets from the model and save mu_hat and p-value
model_test =
  rerun(5000, test_func(mu = 0)) %>% 
  bind_rows() %>% 
  mutate(
    mu_hat = t_test_stats$estimate,
    p_value = t_test_stats$p.value
    ) %>% 
  select(mu_hat, p_value)

model_test

```

```{r}
# repeat for different mu
diff_mu_df = 
  tibble(mu_list = c(1:6)) %>% 
  mutate(output = map(.x = mu_list, ~rerun(5000,test_func(mu = .x)))) %>% 
  bind_rows() %>% 
  unnest() %>% 
  unnest(cols = output) %>% 
  mutate(
    mu_hat = t_test_stats$estimate,
    p_value = t_test_stats$p.value
  ) %>% 
  select(mu_list, mu_hat, p_value)
```

```{r}
# make a plot
plot_1 =
  diff_mu_df %>% 
  group_by(mu_list) %>% 
  summarize(
    total_n = n(), reject_n = sum(p_value<0.05)
  ) %>% 
  mutate(
    reject_prop = reject_n / total_n
  ) %>% 
  ggplot(aes(x = mu_list, y = reject_prop)) + geom_point() + geom_line()+
  labs(title = "mu Value vs Rejection Proportion",x = "True Value of mu", y = "Rejection Proportion") +
  theme(plot.title = element_text(hjust = 0.5)) 

plot_1
```
description: From the plot, there is a general increasing trend, which means as the effect size increases, the power also increases.

```{r}
# make other plots
plot_2 =
  diff_mu_df %>% 
  group_by(mu_list) %>% 
  summarize(
    ave_mu_hat = mean(mu_hat)
  ) %>% 
  ggplot(aes(x = mu_list, y = ave_mu_hat)) + geom_point() + geom_line()+
  labs(title = "True mu vs Average mu (all)",x = "True Value of mu", y = "Average Value of mu") +
  theme(plot.title = element_text(hjust = 0.5)) 
```

```{r}
plot_3  = 
  diff_mu_df %>% 
  filter(p_value < 0.05) %>% 
  group_by(mu_list) %>% 
  summarize(
    ave_mu_hat = mean(mu_hat)
  ) %>% 
  ggplot(aes(x = mu_list, y = ave_mu_hat)) + geom_point() + geom_line()+
  labs(title = "True mu vs Average mu (rejected)",x = "True Value of mu", y = "Average Value of mu") +
  theme(plot.title = element_text(hjust = 0.5)) 
```

```{r}
plot_2 + plot_3
```
description: from the right plot (for only rejected ones), as true value of mu increases, the average value of mu get closer to the true value, but when effect size is small, there are some deviations between average value and true value of mu because the power increases with the increase in effect size.